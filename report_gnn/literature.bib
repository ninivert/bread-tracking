@misc{vadot_cs-433_2021,
	title = {{CS}-433 project 2 source code},
	url = {https://github.com/CS-433/ml-project-2-bread},
	author = {Vadot, Niels},
	month = dec,
	year = {2021},
}


@article{kipf_semi-supervised_2017,
	title = {Semi-{Supervised} {Classification} with {Graph} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1609.02907},
	abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
	urldate = {2021-12-16},
	journal = {arXiv:1609.02907 [cs, stat]},
	author = {Kipf, Thomas N. and Welling, Max},
	month = {feb},
	year = {2017},
	note = {arXiv: 1609.02907},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{dezoort_charged_2021,
	title = {Charged particle tracking via edge-classifying interaction networks},
	url = {http://arxiv.org/abs/2103.16701},
	abstract = {Recent work has demonstrated that geometric deep learning methods such as graph neural networks (GNNs) are well suited to address a variety of reconstruction problems in high energy particle physics. In particular, particle tracking data is naturally represented as a graph by identifying silicon tracker hits as nodes and particle trajectories as edges; given a set of hypothesized edges, edge-classifying GNNs identify those corresponding to real particle trajectories. In this work, we adapt the physics-motivated interaction network (IN) GNN toward the problem of particle tracking in pileup conditions similar to those expected at the high-luminosity Large Hadron Collider. Assuming idealized hit filtering at various particle momenta thresholds, we demonstrate the IN's excellent edge-classification accuracy and tracking efficiency through a suite of measurements at each stage of GNN-based tracking: graph construction, edge classification, and track building. The proposed IN architecture is substantially smaller than previously studied GNN tracking architectures; this is particularly promising as a reduction in size is critical for enabling GNN-based tracking in constrained computing environments. Furthermore, the IN may be represented as either a set of explicit matrix operations or a message passing GNN. Efforts are underway to accelerate each representation via heterogeneous computing resources towards both high-level and low-latency triggering applications.},
	urldate = {2021-12-16},
	journal = {arXiv:2103.16701 [hep-ex]},
	author = {DeZoort, Gage and Thais, Savannah and Duarte, Javier and Razavimaleki, Vesal and Atkinson, Markus and Ojalvo, Isobel and Neubauer, Mark and Elmer, Peter},
	month = {nov},
	year = {2021},
	note = {arXiv: 2103.16701},
	keywords = {Computer Science - Machine Learning, High Energy Physics - Experiment},
}

@article{singer_node_2019,
	title = {Node {Embedding} over {Temporal} {Graphs}},
	url = {http://arxiv.org/abs/1903.08889},
	doi = {10.24963/ijcai.2019/640},
	abstract = {In this work, we present a method for node embedding in temporal graphs. We propose an algorithm that learns the evolution of a temporal graph's nodes and edges over time and incorporates this dynamics in a temporal node embedding framework for different graph prediction tasks. We present a joint loss function that creates a temporal embedding of a node by learning to combine its historical temporal embeddings, such that it optimizes per given task (e.g., link prediction). The algorithm is initialized using static node embeddings, which are then aligned over the representations of a node at different time points, and eventually adapted for the given task in a joint optimization. We evaluate the effectiveness of our approach over a variety of temporal graphs for the two fundamental tasks of temporal link prediction and multi-label node classification, comparing to competitive baselines and algorithmic alternatives. Our algorithm shows performance improvements across many of the datasets and baselines and is found particularly effective for graphs that are less cohesive, with a lower clustering coefficient.},
	urldate = {2021-12-16},
	journal = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	author = {Singer, Uriel and Guy, Ido and Radinsky, Kira},
	month = {aug},
	year = {2019},
	note = {arXiv: 1903.08889},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
	pages = {4605--4612},
}

@techreport{ershov_bringing_2021,
	title = {Bringing {TrackMate} into the era of machine-learning and deep-learning},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.09.03.458852v2},
	abstract = {TrackMate is an automated tracking software used to analyze bioimages and distributed as a Fiji plugin. Here we introduce a new version of TrackMate rewritten to improve performance and usability, and integrating several popular machine and deep learning algorithms to improve versatility. We illustrate how these new components can be used to efficiently track objects from brightfield and fluorescence microscopy images across a wide range of bio-imaging experiments.},
	language = {en},
	urldate = {2021-12-16},
	author = {Ershov, Dmitry and Phan, Minh-Son and Pylvänäinen, Joanna W. and Rigaud, Stéphane U. and Blanc, Laure Le and Charles-Orszag, Arthur and Conway, James R. W. and Laine, Romain F. and Roy, Nathan H. and Bonazzi, Daria and Duménil, Guillaume and Jacquemet, Guillaume and Tinevez, Jean-Yves},
	month = {sep},
	year = {2021},
	note = {Type: article},
	pages = {2021.09.03.458852},
}

@article{cordonnier_extrapolating_2019,
	title = {Extrapolating paths with graph neural networks},
	url = {http://arxiv.org/abs/1903.07518},
	abstract = {We consider the problem of path inference: given a path prefix, i.e., a partially observed sequence of nodes in a graph, we want to predict which nodes are in the missing suffix. In particular, we focus on natural paths occurring as a by-product of the interaction of an agent with a network---a driver on the transportation network, an information seeker in Wikipedia, or a client in an online shop. Our interest is sparked by the realization that, in contrast to shortest-path problems, natural paths are usually not optimal in any graph-theoretic sense, but might still follow predictable patterns. Our main contribution is a graph neural network called Gretel. Conditioned on a path prefix, this network can efficiently extrapolate path suffixes, evaluate path likelihood, and sample from the future path distribution. Our experiments with GPS traces on a road network and user-navigation paths in Wikipedia confirm that Gretel is able to adapt to graphs with very different properties, while also comparing favorably to previous solutions.},
	urldate = {2021-12-16},
	journal = {arXiv:1903.07518 [cs, stat]},
	author = {Cordonnier, Jean-Baptiste and Loukas, Andreas},
	month = {mar},
	year = {2019},
	note = {arXiv: 1903.07518},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@techreport{stringer_cellpose_2020,
	title = {Cellpose: a generalist algorithm for cellular segmentation},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	shorttitle = {Cellpose},
	url = {https://www.biorxiv.org/content/10.1101/2020.02.02.931238v1},
	abstract = {Many biological applications require the segmentation of cell bodies, membranes and nuclei from microscopy images. Deep learning has enabled great progress on this problem, but current methods are specialized for images that have large training datasets. Here we introduce a generalist, deep learning-based segmentation algorithm called Cellpose, which can very precisely segment a wide range of image types out-of-the-box and does not require model retraining or parameter adjustments. We trained Cellpose on a new dataset of highly-varied images of cells, containing over 70,000 segmented objects. To support community contributions to the training data, we developed software for manual labelling and for curation of the automated results, with optional direct upload to our data repository. Periodically retraining the model on the community-contributed data will ensure that Cellpose improves constantly.},
	language = {en},
	urldate = {2021-12-16},
	author = {Stringer, Carsen and Michaelos, Michalis and Pachitariu, Marius},
	month = {feb},
	year = {2020},
	note = {Type: article},
	pages = {2020.02.02.931238},
}

@article{jin_recurrent_2020,
	title = {Recurrent {Event} {Network}: {Autoregressive} {Structure} {Inference} over {Temporal} {Knowledge} {Graphs}},
	shorttitle = {Recurrent {Event} {Network}},
	url = {http://arxiv.org/abs/1904.05530},
	abstract = {Knowledge graph reasoning is a critical task in natural language processing. The task becomes more challenging on temporal knowledge graphs, where each fact is associated with a timestamp. Most existing methods focus on reasoning at past timestamps and they are not able to predict facts happening in the future. This paper proposes Recurrent Event Network (RE-NET), a novel autoregressive architecture for predicting future interactions. The occurrence of a fact (event) is modeled as a probability distribution conditioned on temporal sequences of past knowledge graphs. Specifically, our RE-NET employs a recurrent event encoder to encode past facts and uses a neighborhood aggregator to model the connection of facts at the same timestamp. Future facts can then be inferred in a sequential manner based on the two modules. We evaluate our proposed method via link prediction at future times on five public datasets. Through extensive experiments, we demonstrate the strength of RENET, especially on multi-step inference over future timestamps, and achieve state-of-the-art performance on all five datasets. Code and data can be found at https://github.com/INK-USC/RE-Net.},
	urldate = {2021-12-16},
	journal = {arXiv:1904.05530 [cs, stat]},
	author = {Jin, Woojeong and Qu, Meng and Jin, Xisen and Ren, Xiang},
	month = {oct},
	year = {2020},
	note = {arXiv: 1904.05530},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{rossi_temporal_2020,
	title = {Temporal {Graph} {Networks} for {Deep} {Learning} on {Dynamic} {Graphs}},
	url = {http://arxiv.org/abs/2006.10637},
	abstract = {Graph Neural Networks (GNNs) have recently become increasingly popular due to their ability to learn complex systems of relations or interactions arising in a broad spectrum of problems ranging from biology and particle physics to social networks and recommendation systems. Despite the plethora of different models for deep learning on graphs, few approaches have been proposed thus far for dealing with graphs that present some sort of dynamic nature (e.g. evolving features or connectivity over time). In this paper, we present Temporal Graph Networks (TGNs), a generic, efficient framework for deep learning on dynamic graphs represented as sequences of timed events. Thanks to a novel combination of memory modules and graph-based operators, TGNs are able to significantly outperform previous approaches being at the same time more computationally efficient. We furthermore show that several previous models for learning on dynamic graphs can be cast as specific instances of our framework. We perform a detailed ablation study of different components of our framework and devise the best configuration that achieves state-of-the-art performance on several transductive and inductive prediction tasks for dynamic graphs.},
	urldate = {2021-12-16},
	journal = {arXiv:2006.10637 [cs, stat]},
	author = {Rossi, Emanuele and Chamberlain, Ben and Frasca, Fabrizio and Eynard, Davide and Monti, Federico and Bronstein, Michael},
	month = {oct},
	year = {2020},
	note = {arXiv: 2006.10637},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@incollection{paszke_pytorch_2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d' and Fox, E. and Garnett, R.},
	year = {2019},
	pages = {8024--8035},
}

@article{fey_fast_2019,
	title = {Fast {Graph} {Representation} {Learning} with {PyTorch} {Geometric}},
	url = {http://arxiv.org/abs/1903.02428},
	abstract = {We introduce PyTorch Geometric, a library for deep learning on irregularly structured input data such as graphs, point clouds and manifolds, built upon PyTorch. In addition to general graph data structures and processing methods, it contains a variety of recently published methods from the domains of relational learning and 3D data processing. PyTorch Geometric achieves high data throughput by leveraging sparse GPU acceleration, by providing dedicated CUDA kernels and by introducing efficient mini-batch handling for input examples of different size. In this work, we present the library in detail and perform a comprehensive comparative study of the implemented methods in homogeneous evaluation scenarios.},
	urldate = {2021-12-16},
	journal = {arXiv:1903.02428 [cs, stat]},
	author = {Fey, Matthias and Lenssen, Jan Eric},
	month = {apr},
	year = {2019},
	note = {arXiv: 1903.02428},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{li_deepergcn_2020,
	title = {{DeeperGCN}: {All} {You} {Need} to {Train} {Deeper} {GCNs}},
	shorttitle = {{DeeperGCN}},
	url = {http://arxiv.org/abs/2006.07739},
	abstract = {Graph Convolutional Networks (GCNs) have been drawing significant attention with the power of representation learning on graphs. Unlike Convolutional Neural Networks (CNNs), which are able to take advantage of stacking very deep layers, GCNs suffer from vanishing gradient, over-smoothing and over-fitting issues when going deeper. These challenges limit the representation power of GCNs on large-scale graphs. This paper proposes DeeperGCN that is capable of successfully and reliably training very deep GCNs. We define differentiable generalized aggregation functions to unify different message aggregation operations (e.g. mean, max). We also propose a novel normalization layer namely MsgNorm and a pre-activation version of residual connections for GCNs. Extensive experiments on Open Graph Benchmark (OGB) show DeeperGCN significantly boosts performance over the state-of-the-art on the large scale graph learning tasks of node property prediction and graph property prediction. Please visit https://www.deepgcns.org for more information.},
	urldate = {2021-12-16},
	journal = {arXiv:2006.07739 [cs, stat]},
	author = {Li, Guohao and Xiong, Chenxin and Thabet, Ali and Ghanem, Bernard},
	month = {jun},
	year = {2020},
	note = {arXiv: 2006.07739},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{dietler_convolutional_2020,
	title = {A convolutional neural network segments yeast microscopy images with high accuracy},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-19557-4},
	doi = {10.1038/s41467-020-19557-4},
	abstract = {The identification of cell borders (‘segmentation’) in microscopy images constitutes a bottleneck for large-scale experiments. For the model organism Saccharomyces cerevisiae, current segmentation methods face challenges when cells bud, crowd, or exhibit irregular features. We present a convolutional neural network (CNN) named YeaZ, the underlying training set of high-quality segmented yeast images ({\textgreater}10 000 cells) including mutants, stressed cells, and time courses, as well as a graphical user interface and a web application (www.quantsysbio.com/data-and-software) to efficiently employ, test, and expand the system. A key feature is a cell-cell boundary test which avoids the need for fluorescent markers. Our CNN is highly accurate, including for buds, and outperforms existing methods on benchmark images, indicating it transfers well to other conditions. To demonstrate how efficient large-scale image processing uncovers new biology, we analyze the geometries of ≈2200 wild-type and cyclin mutant cells and find that morphogenesis control occurs unexpectedly early and gradually.},
	language = {en},
	number = {1},
	urldate = {2021-12-16},
	journal = {Nature Communications},
	author = {Dietler, Nicola and Minder, Matthias and Gligorovski, Vojislav and Economou, Augoustina Maria and Joly, Denis Alain Henri Lucien and Sadeghi, Ahmad and Chan, Chun Hei Michael and Koziński, Mateusz and Weigert, Martin and Bitbol, Anne-Florence and Rahi, Sahand Jamal},
	month = {nov},
	year = {2020},
	keywords = {Bioinformatics, Image processing, Software},
	pages = {5723},
}


@article{zhou_graph_2021,
	title = {Graph {Neural} {Networks}: {A} {Review} of {Methods} and {Applications}},
	shorttitle = {Graph {Neural} {Networks}},
	url = {http://arxiv.org/abs/1812.08434},
	abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.},
	urldate = {2021-12-16},
	journal = {arXiv:1812.08434 [cs, stat]},
	author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
	month = {oct},
	year = {2021},
	note = {arXiv: 1812.08434},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}


@ARTICLE{2020SciPy-NMeth,
	author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
	Haberland, Matt and Reddy, Tyler and Cournapeau, David and
	Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
	Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
	Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
	Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
	Kern, Robert and Larson, Eric and Carey, C J and
	Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
	{VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
	Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
	Harris, Charles R. and Archibald, Anne M. and
	Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
	{van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
	title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
	Computing in Python}},
	journal = {Nature Methods},
	year    = {2020},
	volume  = {17},
	pages   = {261--272},
	adsurl  = {https://rdcu.be/b08Wh},
	doi     = {10.1038/s41592-019-0686-2},
}


@article{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2021-12-18},
	journal = {arXiv:1502.03167 [cs]},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv: 1502.03167},
	keywords = {Computer Science - Machine Learning},
}



@article{brody_how_2021,
	title = {How {Attentive} are {Graph} {Attention} {Networks}?},
	url = {http://arxiv.org/abs/2105.14491},
	abstract = {Graph Attention Networks (GATs) are one of the most popular GNN architectures and are considered as the state-of-the-art architecture for representation learning with graphs. In GAT, every node attends to its neighbors given its own representation as the query. However, in this paper we show that GAT computes a very limited kind of attention: the ranking of the attention scores is unconditioned on the query node. We formally define this restricted kind of attention as static attention and distinguish it from a strictly more expressive dynamic attention. Because GATs use a static attention mechanism, there are simple graph problems that GAT cannot express: in a controlled problem, we show that static attention hinders GAT from even fitting the training data. To remove this limitation, we introduce a simple fix by modifying the order of operations and propose GATv2: a dynamic graph attention variant that is strictly more expressive than GAT. We perform an extensive evaluation and show that GATv2 outperforms GAT across 11 OGB and other benchmarks while we match their parametric costs. Our code is available at https://github.com/tech-srl/how\_attentive\_are\_gats , and GATv2 is available as part of the PyTorch Geometric library.},
	urldate = {2021-12-18},
	journal = {arXiv:2105.14491 [cs]},
	author = {Brody, Shaked and Alon, Uri and Yahav, Eran},
	month = oct,
	year = {2021},
	note = {arXiv: 2105.14491},
	keywords = {Computer Science - Machine Learning},
}

@article{velickovic_graph_2018,
	title = {Graph {Attention} {Networks}},
	url = {http://arxiv.org/abs/1710.10903},
	abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
	urldate = {2021-12-18},
	journal = {arXiv:1710.10903 [cs, stat]},
	author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
	month = feb,
	year = {2018},
	note = {arXiv: 1710.10903},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}
